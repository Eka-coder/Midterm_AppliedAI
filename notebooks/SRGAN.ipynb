{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd89fcdd",
   "metadata": {},
   "source": [
    "# SRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy, MeanAbsoluteError\n",
    "from keras.layers import layers, Input, Convolution2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Add, Lambda, LeakyReLU\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.python.keras.layers import PReLU\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import Mean\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets.div2k.parameters import Div2kParameters \n",
    "from datasets.div2k.loader import create_training_and_validation_datasets\n",
    "from utils.normalization import normalize_m11, normalize_01, denormalize_m11\n",
    "from utils.dataset_mappings import random_crop, random_flip, random_rotate, random_lr_jpeg_noise\n",
    "from utils.metrics import psnr_metric\n",
    "from utils.config import config\n",
    "from utils.callbacks import SaveCustomCheckpoint\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - align with your assignment requirements\n",
    "LR_SHAPE = (32, 32, 3)    # Low-resolution input\n",
    "HR_SHAPE = (128, 128, 3)  # High-resolution target \n",
    "SCALING_FACTOR = 4         # 4x upscaling (32→128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Block (basic building block)\n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, filters=64):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.prelu = layers.PReLU()\n",
    "        self.conv2 = layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        return layers.add([inputs, x])\n",
    "\n",
    "# Generator Network\n",
    "def build_generator():\n",
    "    inputs = Input(shape=LR_SHAPE)\n",
    "    \n",
    "    # Initial feature extraction\n",
    "    x = layers.Conv2D(64, 9, padding='same', activation='relu')(inputs)\n",
    "    initial = x\n",
    "    \n",
    "    # Residual blocks (use 16 as in reference)\n",
    "    for _ in range(16):\n",
    "        x = ResidualBlock(64)(x)\n",
    "    \n",
    "    # Skip connection\n",
    "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.add([initial, x])\n",
    "    \n",
    "    # Upsampling blocks (2x each, total 4x)\n",
    "    x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "    x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)  # PixelShuffle\n",
    "    x = layers.PReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "    x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)  # PixelShuffle\n",
    "    x = layers.PReLU()(x)\n",
    "    \n",
    "    # Final output\n",
    "    x = layers.Conv2D(3, 9, padding='same', activation='tanh')(x)\n",
    "    \n",
    "    return Model(inputs, x)\n",
    "\n",
    "# Discriminator Network  \n",
    "def build_discriminator():\n",
    "    inputs = Input(shape=HR_SHAPE)\n",
    "    \n",
    "    # Feature extraction with increasing filters\n",
    "    x = layers.Conv2D(64, 3, padding='same')(inputs)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    for filters in [128, 256, 512]:\n",
    "        x = layers.Conv2D(filters, 3, strides=2, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs, x)\n",
    "\n",
    "# VGG-based Perceptual Loss\n",
    "def build_vgg_loss():\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', \n",
    "                                      input_shape=HR_SHAPE)\n",
    "    vgg.trainable = False\n",
    "    # Use block5_conv4 features for perceptual loss as referenced\n",
    "    return Model(vgg.input, vgg.get_layer('block5_conv4').output)\n",
    "\n",
    "# Combined SRGAN Model\n",
    "class SRGAN(keras.Model):\n",
    "    def __init__(self, generator, discriminator, vgg):\n",
    "        super(SRGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.vgg = vgg\n",
    "        \n",
    "    def compile(self, g_optimizer, d_optimizer, **kwargs):\n",
    "        super(SRGAN, self).compile(**kwargs)\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        \n",
    "    def train_step(self, batch_data):\n",
    "        hr_imgs, lr_imgs = batch_data\n",
    "        \n",
    "        # Train Discriminator\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            generated_imgs = self.generator(lr_imgs, training=False)\n",
    "            \n",
    "            real_output = self.discriminator(hr_imgs, training=True)\n",
    "            fake_output = self.discriminator(generated_imgs, training=True)\n",
    "            \n",
    "            d_real_loss = keras.losses.binary_crossentropy(tf.ones_like(real_output), real_output)\n",
    "            d_fake_loss = keras.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output)\n",
    "            d_loss = tf.reduce_mean(d_real_loss + d_fake_loss) / 2\n",
    "            \n",
    "        d_grads = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Train Generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            generated_imgs = self.generator(lr_imgs, training=True)\n",
    "            fake_output = self.discriminator(generated_imgs, training=False)\n",
    "            \n",
    "            # Adversarial loss\n",
    "            g_adv_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(tf.ones_like(fake_output), fake_output))\n",
    "            \n",
    "            # Perceptual loss (VGG-based)\n",
    "            real_features = self.vgg(hr_imgs)\n",
    "            fake_features = self.vgg(generated_imgs)\n",
    "            g_perceptual_loss = tf.reduce_mean(\n",
    "                keras.losses.mean_squared_error(real_features, fake_features))\n",
    "            \n",
    "            # Total generator loss\n",
    "            g_loss = 1e-3 * g_adv_loss + g_perceptual_loss\n",
    "            \n",
    "        g_grads = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss, \"g_adv_loss\": g_adv_loss, \"g_perceptual_loss\": g_perceptual_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation function\n",
    "def prepare_srgan_data(dataset_path, split_ratio=0.7):\n",
    "    \"\"\"Prepare HR/LR pairs for SRGAN training\"\"\"\n",
    "    # Load your dataset similar to your current approach\n",
    "    full_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset_path,\n",
    "        label_mode=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=HR_SHAPE[:2],\n",
    "        shuffle=True,\n",
    "        seed=123\n",
    "    )\n",
    "    \n",
    "    # Normalize and split\n",
    "    full_ds = full_ds.map(lambda x: tf.cast(x, tf.float32) / 127.5 - 1.0)\n",
    "    \n",
    "    # Create LR versions (32×32) and keep HR (128×128)\n",
    "    def create_hr_lr_pairs(hr_img):\n",
    "        lr_img = tf.image.resize(hr_img, LR_SHAPE[:2], method='area')  # Downsample\n",
    "        return (hr_img, lr_img)\n",
    "    \n",
    "    paired_ds = full_ds.map(create_hr_lr_pairs)\n",
    "    \n",
    "    # Split for training (70%) and testing (30%) as required\n",
    "    dataset_size = len(list(paired_ds))\n",
    "    train_size = int(split_ratio * dataset_size)\n",
    "    \n",
    "    train_ds = paired_ds.take(train_size).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = paired_ds.skip(train_size).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, test_ds\n",
    "\n",
    "# Training execution\n",
    "def train_srgan():\n",
    "    # Build models\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator() \n",
    "    vgg = build_vgg_loss()\n",
    "    \n",
    "    # Create SRGAN\n",
    "    srgan = SRGAN(generator, discriminator, vgg)\n",
    "    \n",
    "    # Compile with optimizers\n",
    "    srgan.compile(\n",
    "        g_optimizer=keras.optimizers.Adam(1e-4),\n",
    "        d_optimizer=keras.optimizers.Adam(1e-4),\n",
    "    )\n",
    "    \n",
    "    # Load your data\n",
    "    train_ds, test_ds = prepare_srgan_data('C:/Users/lolze/Documents/Github/Midterm_AppliedAI/data/processed_128')\n",
    "    \n",
    "    # Callbacks for saving models (critical for Colab)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        'srgan_weights_epoch_{epoch:02d}.h5',\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "    \n",
    "    # Train for 150+ epochs as required\n",
    "    history = srgan.fit(\n",
    "        train_ds,\n",
    "        epochs=150,\n",
    "        callbacks=[checkpoint_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return srgan, history"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
