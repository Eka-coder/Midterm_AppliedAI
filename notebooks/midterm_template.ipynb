{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b312ff6",
   "metadata": {},
   "source": [
    "# Applied AI Midterm Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c32a2c",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "TODO: Install required packages if needed, import torch, torchvision, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add imports\n",
    "from keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e0385",
   "metadata": {},
   "source": [
    "## 2. Load Dataset and Preprocessing\n",
    "- TODO: Load dataset\n",
    "- TODO: Apply 128x128 resize transformation for classifiers\n",
    "- TODO: Generate 32x32 LR images for SRGAN\n",
    "- TODO: Show sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load and preprocess datasets\n",
    "img_width, img_height, img_depth = 128, 128, 3\n",
    "import cv2\n",
    "\n",
    "def load_images_from_folder(folder, img_size=(img_width,img_height)):\n",
    "    images, labels = [], []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            images.append(path)\n",
    "            if str(filename).startswith(\"cat\"):\n",
    "                labels.append(\"cat\")\n",
    "            elif str(filename).startswith(\"dog\"):\n",
    "                labels.append(\"dog\")\n",
    "    df = pd.DataFrame({\n",
    "        'Image': images,\n",
    "        'Class': labels\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_images_from_folder(\"train\")\n",
    "\n",
    "def split_dataframe_three_ways(df, train_ratio=0.6, valid_ratio=0.2, test_ratio=0.2, random_state=1):\n",
    "    \"\"\"\n",
    "    Split DataFrame into train, validation, and test sets\n",
    "    \"\"\"\n",
    "    assert train_ratio + valid_ratio + test_ratio == 1.0, \"Ratios must sum to 1.0\"\n",
    "    \n",
    "    # First, split out test set\n",
    "    df_temp, df_test = train_test_split(\n",
    "        df, \n",
    "        test_size=test_ratio, \n",
    "        random_state=random_state, \n",
    "        stratify=df['Class']\n",
    "    )\n",
    "    \n",
    "    # Then split remaining into train and validation\n",
    "    remaining_ratio = 1.0 - test_ratio\n",
    "    valid_size = valid_ratio / remaining_ratio\n",
    "    \n",
    "    df_train, df_valid = train_test_split(\n",
    "        df_temp, \n",
    "        test_size=valid_size, \n",
    "        random_state=random_state, \n",
    "        stratify=df_temp['Class']\n",
    "    )\n",
    "    \n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "# Usage\n",
    "df_train, df_valid, df_test = split_dataframe_three_ways(df, train_ratio=0.6, valid_ratio=0.2, test_ratio=0.2)\n",
    "nb_train_samples = len(df_train)\n",
    "nb_valid_samples = len(df_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14820e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training parameters\n",
    "epochs = 50\n",
    "freq = 20\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "train_valid_split = 0.2\n",
    "\n",
    "act_type = 'sigmoid'\n",
    "class_mode = 'binary'\n",
    "loss_fun = 'binary_crossentropy'\n",
    "\n",
    "fold_num = 1\n",
    "path = 'split_train/train'\n",
    "\n",
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_width, img_height),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=train_valid_split,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "ds_valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_width, img_height),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=train_valid_split,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Use tf.keras.layers.preprocessing for augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.5),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2)\n",
    "    # Rotates by up to 90 degrees (0.5 * 180)\n",
    "])\n",
    "\n",
    "# Prepare the datasets for training and validation\n",
    "# Apply data augmentation only to the training dataset\n",
    "ds_train = ds_train.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# You might want to add a rescaling layer as the first layer in your model\n",
    "# instead of in the data augmentation pipeline, as it's applied to all data.\n",
    "# However, for demonstration, we can include it here.\n",
    "rescale = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "ds_train = ds_train.map(lambda x, y: (rescale(x), y))\n",
    "ds_valid = ds_valid.map(lambda x, y: (rescale(x), y))\n",
    "\n",
    "# Optimize performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "ds_valid = ds_valid.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4214586",
   "metadata": {},
   "source": [
    "## 3. Train Classifier A\n",
    "- TODO: Implement transfer learning model (EfficientNet/ResNet)\n",
    "- TODO: Train baseline classifier\n",
    "- TODO: Save best model\n",
    "- TODO: Evaluate performance (Confusion matrix, ROC, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce053786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform transfer learning by using various pre-trained models\n",
    "# Build Model\n",
    "image_input = Input(shape = (img_width, img_height, img_depth))\n",
    "vgg_model = applications.vgg16.VGG16(input_tensor = image_input,\n",
    "                                 include_top = False,\n",
    "                                 weights = 'imagenet')\n",
    "\n",
    "vgg_output = vgg_model.layers[-1].output\n",
    "\n",
    "flat1 = Flatten()(vgg_output)\n",
    "fc1 = Dense(512, activation = 'relu')(flat1)\n",
    "dropfc1 = Dropout(0.5)(fc1)\n",
    "fc2 = Dense(256, activation = 'relu')(dropfc1)\n",
    "dropfc2 = Dropout(0.5)(fc2)\n",
    "\n",
    "output = Dense(1, activation = act_type)(dropfc2)\n",
    "\n",
    "for layer in vgg_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Model(image_input, output)\n",
    "\n",
    "# Compile the model\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "model.compile(loss = loss_fun, optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "# Folder setup\n",
    "fold_num = 1\n",
    "\n",
    "init_time = datetime.now()\n",
    "current_time = init_time.strftime('%Y%m%d_%H%M%S')\n",
    "name_dir = 'models/'+'ClassA' + current_time + '_fold_num' + str(fold_num)\n",
    "os.mkdir(name_dir)\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='./logs',          # Directory for logs\n",
    "    histogram_freq=1,          # How often to compute histograms\n",
    "    write_graph=True,          # Write computation graph\n",
    "    write_images=True          # Write model weights as images\n",
    ")\n",
    "\n",
    "\n",
    "# Callbacks3: EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "figure_name = name_dir + '/model_output.png'\n",
    "plot_model(model, figure_name, show_shapes = True)\n",
    "\n",
    "# Display model\n",
    "model.summary()\n",
    "history = model.fit(ds_train,\n",
    "                              epochs = epochs,\n",
    "                              steps_per_epoch = 16000 // batch_size,\n",
    "                              validation_data = ds_valid,\n",
    "                              validation_steps = 4000 // batch_size,\n",
    "                              verbose=1,\n",
    "                              callbacks = [early_stop, tensorboard])\n",
    "\n",
    "early_stop_name = name_dir + '/fold_num_' + str(fold_num) + 'early_stop_model.weights.h5'\n",
    "model.save_weights(early_stop_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5315e3",
   "metadata": {},
   "source": [
    "## 4. Build SRGAN (Generator + Discriminator)\n",
    "- TODO: Implement Generator model\n",
    "- TODO: Implement Discriminator model\n",
    "- TODO: Perceptual loss (VGG19)\n",
    "- TODO: GAN training loop with checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7956dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SRGAN model architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3a9bb",
   "metadata": {},
   "source": [
    "## 5. Train SRGAN\n",
    "- TODO: Train for â‰¥150 epochs\n",
    "- TODO: Save checkpoints every n epochs\n",
    "- TODO: Visualize generated results across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cbec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SRGAN training loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd91fd",
   "metadata": {},
   "source": [
    "## 6. Generate New High-Resolution Images\n",
    "- TODO: Use trained SRGAN to generate HR images\n",
    "- TODO: Visualize some HR generated samples\n",
    "- TODO: Save generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d848f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate HR data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4c682",
   "metadata": {},
   "source": [
    "## 7. Train Classifier B with GAN Data\n",
    "- TODO: Load generated HR data\n",
    "- TODO: Train new classifier using combined or synthetic data\n",
    "- TODO: Save best model\n",
    "- TODO: Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Classifier B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1bd29",
   "metadata": {},
   "source": [
    "## 8. Final Evaluation & Comparison\n",
    "- TODO: Compare Classifier A vs Classifier B\n",
    "- TODO: Display metrics table\n",
    "- TODO: Plot ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4620860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Final evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1809ec9e",
   "metadata": {},
   "source": [
    "## 9. Save Outputs\n",
    "- TODO: Export metrics, samples, and models as required"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
