{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207acb4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# Image size\n",
    "img_width, img_height, img_depth = 150, 150, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd38db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training parameters\n",
    "epochs = 50\n",
    "freq = 20\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "train_valid_split = 0.2\n",
    "\n",
    "act_type = 'sigmoid'\n",
    "class_mode = 'binary'\n",
    "loss_fun = 'binary_crossentropy'\n",
    "\n",
    "fold_num = 1\n",
    "#TODO: Change path\n",
    "path = 'split_train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_width, img_height),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=train_valid_split,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "ds_valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_width, img_height),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=train_valid_split,\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.keras.layers.preprocessing for augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.5),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2)\n",
    "    # Rotates by up to 90 degrees (0.5 * 180)\n",
    "])\n",
    "\n",
    "# Prepare the datasets for training and validation\n",
    "# Apply data augmentation only to the training dataset\n",
    "ds_train = ds_train.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# You might want to add a rescaling layer as the first layer in your model\n",
    "# instead of in the data augmentation pipeline, as it's applied to all data.\n",
    "# However, for demonstration, we can include it here.\n",
    "rescale = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "ds_train = ds_train.map(lambda x, y: (rescale(x), y))\n",
    "ds_valid = ds_valid.map(lambda x, y: (rescale(x), y))\n",
    "\n",
    "# Optimize performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "ds_valid = ds_valid.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefe711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 Model\n",
    "image_input = Input(shape = (img_width, img_height, img_depth))\n",
    "res_model = applications.ResNet152V2(input_tensor = image_input,\n",
    "                                 include_top = False,\n",
    "                                 weights = 'imagenet')\n",
    "res_output = res_model.layers[-1].output\n",
    "\n",
    "flat1 = Flatten()(res_output)\n",
    "fc1 = Dense(512, activation = 'relu')(flat1)\n",
    "dropfc1 = Dropout(0.5)(fc1)\n",
    "fc2 = Dense(256, activation = 'relu')(dropfc1)\n",
    "dropfc2 = Dropout(0.5)(fc2)\n",
    "\n",
    "output_res = Dense(1, activation = act_type)(dropfc2)\n",
    "\n",
    "for layer in res_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_res = Model(image_input, output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f458dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "model_res.compile(loss = loss_fun, optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder setup\n",
    "fold_num = 1\n",
    "\n",
    "init_time = datetime.now()\n",
    "current_time = init_time.strftime('%Y%m%d_%H%M%S')\n",
    "name_dir = 'res_trained_models_' + current_time + '_fold_num' + str(fold_num)\n",
    "os.mkdir(name_dir)\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='./logs',          # Directory for logs\n",
    "    histogram_freq=1,          # How often to compute histograms\n",
    "    write_graph=True,          # Write computation graph\n",
    "    write_images=True          # Write model weights as images\n",
    ")\n",
    "\n",
    "# Callbacks3: EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d103acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_res = model_res.fit(ds_train,\n",
    "                              epochs = epochs,\n",
    "                              steps_per_epoch = 16000 // batch_size,\n",
    "                              validation_data = ds_valid,\n",
    "                              validation_steps = 4000 // batch_size,\n",
    "                              verbose=1,\n",
    "                              callbacks = [early_stop, tensorboard])\n",
    "\n",
    "early_stop_name = name_dir + '/fold_num_' + str(fold_num) + 'res_early_stop_model.weights.h5'\n",
    "model_res.save_weights(early_stop_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
